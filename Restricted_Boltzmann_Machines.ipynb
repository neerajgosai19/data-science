{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Restricted Boltzmann Machines ",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSMpakUdVLC+f8/+Yb7eyJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neerajgosai19/data-science/blob/master/Restricted_Boltzmann_Machines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ychORVR3IOUh"
      },
      "source": [
        "import urllib.request\n",
        "with urllib.request.urlopen(\"http://deeplearning.net/tutorial/code/utils.py\") as url:\n",
        "  response = url.read()\n",
        "target = open('utils.py' , 'w')\n",
        "target.write(response.decode('utf-8'))\n",
        "target.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pcyyRfoIstC",
        "outputId": "7118280e-7f44-4ae0-bf05-ac3abb21afde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install grpcio\n",
        "!pip install tensorflow==2.2.0\n",
        "!pip install pillow\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.6/dist-packages (1.32.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from grpcio) (1.15.0)\n",
            "Collecting tensorflow==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 516.2MB 25kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 460kB 37.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.10.0)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.0MB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.18.5)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (50.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.17.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi7sNLd9Isvf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from IPython.display import Markdown , display\n",
        "def printmd(string):\n",
        "  display(Markdown('# < span style = \"color:blue\">' + string + '</span>'))\n",
        "if not tf.__version__ == '2.2.0':\n",
        "  printmd('<<<<<!!!!! ERROR !!!! please upgrade to TensorFlow 2.2.0, or restart your Kernel (Kernel->Restart & Clear Output)>>>>>')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR53ZojHIszt"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from utils import tile_raster_images\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHeMOgBxIs4K"
      },
      "source": [
        "v_bias = tf.Variable(tf.zeros([7]), tf.float32)\n",
        "h_bias = tf.Variable(tf.zeros([2]), tf.float32)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3ifuVlsIs9E"
      },
      "source": [
        "W = tf.constant(np.random.normal(loc= 0.0 , scale = 1.0 , size=(7,2)).astype(np.float32))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kky2LVR2HHsd"
      },
      "source": [
        "Before we go further, let's look at a toy example for one case out of all input. Assume that we have a trained RBM, and a very simple input vector, such as [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FHbTju9ItGK",
        "outputId": "d57255b1-e410-41da-8aaa-e5e7b2eae0ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = tf.constant([[1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]],tf.float32)\n",
        "v_state = X\n",
        "print('v_State input is   :' , v_state)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v_State input is   : tf.Tensor([[1. 0. 0. 1. 0. 0. 0.]], shape=(1, 7), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG3j5hI3ItL2",
        "outputId": "3bf5637a-3081-4249-8754-8455a8bce203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "h_bias = tf.constant([0.1, 0.1])\n",
        "print('hb : ' , h_bias)\n",
        "print( 'W' , W)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hb :  tf.Tensor([0.1 0.1], shape=(2,), dtype=float32)\n",
            "W tf.Tensor(\n",
            "[[ 1.5673054  -2.1570647 ]\n",
            " [-0.2501203  -0.2890857 ]\n",
            " [-0.99101835 -0.00397976]\n",
            " [ 0.5386768   0.75148547]\n",
            " [ 0.54450536  0.5033698 ]\n",
            " [-0.02519927 -0.74991506]\n",
            " [-0.588251    0.5456763 ]], shape=(7, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWRi2jA9ItQF",
        "outputId": "ff998eee-4eb4-44eb-889f-ab8c2f6e778b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the probabilities of turning the hidden units on:\n",
        "h_prob = tf.nn.sigmoid(tf.matmul(v_state, W) + h_bias)\n",
        "print(\"p(h|v):\" , h_prob)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p(h|v): tf.Tensor([[0.9007855  0.21322756]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUguisPTItVP",
        "outputId": "e7ec34d1-7fba-4448-81f0-1c50fe81f785",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Draw samples from the distribution:\n",
        "h_state = tf.nn.relu(tf.sign(h_prob - tf.random.uniform(tf.shape(h_prob))))\n",
        "print(\"h0 states: \" , h_state )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h0 states:  tf.Tensor([[1. 0.]], shape=(1, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaznS86KUDNU"
      },
      "source": [
        "phase 2) Backward Pass (Reconstruction): The RBM reconstructs data by making several forward and backward passes between the visible and hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaU5m5twItTv",
        "outputId": "77b4c7fb-7f46-41fb-f16b-2c2b0b81407d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vb = tf.constant([0.1, 0.2, 0.1, 0.1, 0.1, 0.2, 0.1])\n",
        "print (\"b   :\"   , vb)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b   : tf.Tensor([0.1 0.2 0.1 0.1 0.1 0.2 0.1], shape=(7,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc7CqNuwItOi",
        "outputId": "ccdc01f8-ee91-43f5-b44b-0021bc85d067",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "v_prob = tf.nn.sigmoid(tf.matmul(h_state , tf.transpose(W)) + vb)\n",
        "print(\"p(vi‚à£h)\" , v_prob)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p(vi‚à£h) tf.Tensor(\n",
            "[[0.8412162  0.48747256 0.29089972 0.6544543  0.6557712  0.54358923\n",
            "  0.38030568]], shape=(1, 7), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLsTaGMAYo08"
      },
      "source": [
        " with probability  ùëù(‚Ñéùëó|ùëöùëéùë°‚Ñéùëèùëìùë£) , and turn it off with probability  1‚àíùëù(‚Ñéùëó|ùëöùëéùë°‚Ñéùëèùëìùë£)  by generating a uniform random number vector  ùëöùëéùë°‚Ñéùëèùëìùë•ùëñ , and comparing it to the activation probability as\n",
        "\n",
        "If  ùúâùëó>ùëù(‚Ñéùëó|ùêØ) , then  ‚Ñéùëó=1 , else  ‚Ñéùëó=0 ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql1iFMZvItKI",
        "outputId": "4377882e-1595-428a-955c-6c0ff330315d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "v_state = tf.nn.relu(tf.sign(v_prob - tf.random.uniform(tf.shape(v_prob))))\n",
        "print(\"v probability states: \"  , v_state )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v probability states:  tf.Tensor([[1. 0. 1. 0. 0. 1. 1.]], shape=(1, 7), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiFDw1e5ItEh",
        "outputId": "eb5c9006-785c-40bc-ebb5-5bf1a21888f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inp = X\n",
        "print(\"input X   :\" ,  inp.numpy())\n",
        "print(\"probablity vector:\" , v_prob[0].numpy())\n",
        "v_probability = 1\n",
        "for elm , p in zip(inp[0],v_prob[0]):\n",
        "  if elm == 1:\n",
        "    v_probability *= p\n",
        "  else:\n",
        "    v_probability *= (1-p)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input X   : [[1. 0. 0. 1. 0. 0. 0.]]\n",
            "probablity vector: [0.8412162  0.48747256 0.29089972 0.6544543  0.6557712  0.54358923\n",
            " 0.38030568]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2shsjbAIs_m",
        "outputId": "6f72ebb7-a8be-4de0-a16b-362e0b4063b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#loading training and test data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(trX , trY) , (teX , teY) = mnist.load_data()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U4Hmx6vXoCs"
      },
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "flatten = Flatten(dtype = 'float32')\n",
        "trX = flatten(trX/255.0)\n",
        "trY = flatten(trY/255.0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8NIzWB2XFgs"
      },
      "source": [
        "#MNIST images have 784 pixels, so the visible layer must have 784 input nodes. For our case, we'll use 50 nodes in the hidden layer, so i = 50.\n",
        "vb = tf.Variable(tf.zeros([784]), dtype= tf.float32)\n",
        "hb = tf.Variable(tf.zeros([50]) , dtype= tf.float32)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew1YmLcJXFli",
        "outputId": "5d20d93f-d73f-4363-a955-67113eee5aa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "W = tf.Variable(tf.zeros([784,50]) , dtype= tf.float32)\n",
        "visi = tf.Variable(tf.zeros([784]) , dtype= tf.float32)\n",
        "tf.matmul([visi ], W)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 50), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeEjNSDYXFot",
        "outputId": "7788375a-15bb-4527-f085-889cd1e02d41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hb_prob = tf.nn.sigmoid(tf.matmul([visi] , W )+ hb)\n",
        "print(\"h0_state shape:\" , tf.shape(hb_prob))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h0_state shape: tf.Tensor([ 1 50], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29nJMPrtXFjv",
        "outputId": "7c91b607-7e7a-4538-b63d-b92b10075157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#defining a function to return only the generated hidden states \n",
        "def hidden_layer(visi , W , hb):\n",
        "  hid_prob = tf.nn.sigmoid(tf.matmul([visi ], W) + hb)  #probabilities of the hidden units\n",
        "  hid_State = tf.nn.relu(tf.sign(hid_prob - tf.random.uniform(tf.shape(hid_prob))))\n",
        "  return hid_State\n",
        "hid_State = hidden_layer(visi , W , hb)\n",
        "print(\"first 15 hidden states  : \"   , hid_State[0][0:15])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first 15 hidden states  :  tf.Tensor([0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.], shape=(15,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQOH4iDBIs7R",
        "outputId": "2421edcf-873d-4f52-d1f8-718a4fb2ed9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Now, we define reconstruction part:\n",
        "def reconstructed_output(hid_State , W , hb):\n",
        "  v1_prob = tf.nn.sigmoid(tf.matmul(hid_State ,tf.transpose(W)) + vb)\n",
        "  v1_State = tf.nn.relu(tf.sign(v1_prob - tf.random.uniform(tf.shape(v1_prob))))\n",
        "  return v1_State\n",
        "v1_State = reconstructed_output(hid_State , W , hb)\n",
        "print(\"hidden state shape: \" , hid_State.shape )\n",
        "print(\"visi state shape:  \", visi.shape )\n",
        "print(\"v1 state shape:  \",  v1_State.shape  )"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden state shape:  (1, 50)\n",
            "visi state shape:   (784,)\n",
            "v1 state shape:   (1, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRqUWUxBM2RH"
      },
      "source": [
        "Calculate error:\n",
        "In each epoch, we compute the \"error\" as a sum of the squared difference between step 1 and step n, e.g the error shows the difference between the data and its reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evPOGmFVIsyz",
        "outputId": "6c843ae3-83ab-418d-fd94-85e1a1e31c3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def error_Calculate(visi , v1_State):\n",
        "  return tf.reduce_mean(tf.square(visi - v1_State))\n",
        "err = tf.reduce_mean(tf.square(visi - v1_State))\n",
        "print(\"the error is :  \" , err.numpy())\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the error is :   0.51403064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDcNSjPjZMoc",
        "outputId": "84c32456-9107-45db-9712-25d6e461a30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "h1_prob = tf.nn.sigmoid(tf.matmul([v1_State ], W ) +  hb )\n",
        "h1_State = tf.nn.relu(tf.sign(h1_prob - tf.random.uniform(tf.shape(h1_prob))))\n",
        "print(\" error :  \"   , v1_State , visi )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " error :   tf.Tensor(\n",
            "[[1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
            "  1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            "  1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
            "  0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1.\n",
            "  1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1.\n",
            "  1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0.\n",
            "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1.\n",
            "  0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            "  1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
            "  1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.\n",
            "  1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            "  1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
            "  0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
            "  0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            "  0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            "  1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0.\n",
            "  0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.\n",
            "  1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            "  0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            "  1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            "  0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1.\n",
            "  1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            "  1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1.\n",
            "  0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0.\n",
            "  1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1.\n",
            "  0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0.\n",
            "  1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            "  0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1.\n",
            "  0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0.\n",
            "  1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0.]], shape=(1, 784), dtype=float32) <tf.Variable 'Variable:0' shape=(784,) dtype=float32, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0.], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgitDTg1wQaQ"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS2VdGYVZMxI"
      },
      "source": [
        "#Parameters\n",
        "alpha = 0.01\n",
        "epochs = 1\n",
        "batchsize = 200\n",
        "weights = []\n",
        "errors = []\n",
        "batch_number = 0\n",
        "K = 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8xvFrU-ZM8w",
        "outputId": "062eac76-f081-4396-8fca-6e63d6e87a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#creating datasets\n",
        "train_ds = \\\n",
        "  tf.data.Dataset.from_tensor_slices((trX , trY)).batch(batchsize)\n",
        "\n",
        "for epoch in range (epochs):\n",
        "  for batch_X , batch_Y in train_ds:\n",
        "    batch_number += 1 \n",
        "    for i_Sample in range(batchsize):\n",
        "      for k in range(K):\n",
        "        visi = batch_X[i_Sample]\n",
        "        hid_State = hidden_layer(visi , W , hb)\n",
        "        v1_State = reconstructed_output(hid_State , W , vb)\n",
        "        h1_State = hidden_layer(v1_State , W , hb)\n",
        "\n",
        "delta_W = tf.matmul(tf.transpose([visi]) , hid_State) - tf.matmul(tf.transpose([v1_State]), h1_State)\n",
        "W = W + alpha* delta_W\n",
        "vb = vb + alpha*tf.reduce_mean(visi - v1_State, 0 )\n",
        "hb = hb + alpha*tf.reduce_mean(hid_State - h1_State , 0)\n",
        "visi = v1_State\n",
        "if i_sample == batchsize-1:\n",
        "                err = error(batch_x[i_sample], v1_state)\n",
        "                errors.append(err)\n",
        "                weights.append(W)\n",
        "                print ( 'Epoch: %d' % epoch, \"batch #: %i \" % batch_number, \"of %i\" % 60e3/batchsize /n)\n",
        "                        \n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-14ff8c767f3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mvisi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_Sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mhid_State\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mhb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mv1_State\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreconstructed_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_State\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mh1_State\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1_State\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mhb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-dfc64269e6c1>\u001b[0m in \u001b[0;36mreconstructed_output\u001b[0;34m(hid_State, W, hb)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Now, we define reconstruction part:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreconstructed_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_State\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mhb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mv1_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_State\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mv1_State\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1_prob\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mv1_State\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2944\u001b[0m         \u001b[0madjoint_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m       return gen_math_ops.batch_mat_mul_v2(\n\u001b[0;32m-> 2946\u001b[0;31m           a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n\u001b[0m\u001b[1;32m   2947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2948\u001b[0m     \u001b[0;31m# Neither matmul nor sparse_matmul support adjoint, so we conjugate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mbatch_mat_mul_v2\u001b[0;34m(x, y, adj_x, adj_y, name)\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1517\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1518\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madj_x\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: In[0] and In[1] must have compatible batch dimensions: [784,1,50] vs. [50,784,784] [Op:BatchMatMulV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnOYi2mhM4Fr"
      },
      "source": [
        "#Parameters\n",
        "alpha = 0.01\n",
        "epochs = 1\n",
        "batchsize = 200\n",
        "weights = []\n",
        "errors = []\n",
        "batch_number = 0\n",
        "K = 1\n",
        "\n",
        "#creating datasets\n",
        "train_ds = \\\n",
        "    tf.data.Dataset.from_tensor_slices((trX, trY)).batch(batchsize)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch_x, batch_y in train_ds:\n",
        "        batch_number += 1\n",
        "        for i_sample in range(batchsize):           \n",
        "            for k in range(K):\n",
        "                v0_state = batch_x[i_sample]\n",
        "                h0_state = hidden_layer(v0_state, W, hb)\n",
        "                v1_state = reconstructed_output(h0_state, W, vb)\n",
        "                h1_state = hidden_layer(v1_state, W, hb)\n",
        "\n",
        "                delta_W = tf.matmul(tf.transpose([v0_state]), h0_state) - tf.matmul(tf.transpose([v1_state]), h1_state)\n",
        "                W = W + alpha * delta_W\n",
        "\n",
        "                vb = vb + alpha * tf.reduce_mean(v0_state - v1_state, 0)\n",
        "                hb = hb + alpha * tf.reduce_mean(h0_state - h1_state, 0) \n",
        "\n",
        "                v0_state = v1_state\n",
        "\n",
        "            if i_sample == batchsize-1:\n",
        "                err = error(batch_x[i_sample], v1_state)\n",
        "                errors.append(err)\n",
        "                weights.append(W)\n",
        "                print ( 'Epoch: %d' % epoch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwbZH3jxM4LB"
      },
      "source": [
        " if i_sample == batchsize-1:\n",
        "                err = error(batch_x[i_sample], v1_state)\n",
        "                errors.append(err)\n",
        "                weights.append(W)\n",
        "                print ( 'Epoch: %d' % epoch, \n",
        "                       \"batch #: %i \" % batch_number, \"of %i\" % 60e3/batchsize \n",
        "                       \"sample #: %i\" % i_sample,\n",
        "                       'reconstruction error: %f' % err)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDtuy-5rM4Q5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjnNqAxHM4Pr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWwxV5gvM4Iv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwj4jjZ7IsqR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}